# 기업협업 프로젝트

​	기업협업 프로젝트를 같이 진행하게된 기업은 팬이 유튜브, 트위치, 혹은 아프리카에서 활동하는 셀럽에게 선물을 보내는 서비스를 제공한다. 기업에서 기업에 등록된 각 셀럽들의 흥망성쇠를 파악할 수 있는 요소를 크롤링하는 작업을 요청하였다. 구체적으로 셀럽의 흥망성쇠 지표라고 볼 수 있는 셀럽의 구독자수나 동영상 조회수, 좋아요수 등을 크롤링했다. 이번 프로젝트에서 트위치 셀럽들의 정보 크롤링과 데몬 제작 역할을 맡았으며 사용한 기술 스텍으로서 파이썬, 장고, MySQL, 크론텝을 사용했다.



## 기술스택

​	기업협업 프로젝트를 하기 전에는 주로 자바스크립트와 Node.js를 사용했다. 그러나 새로운 시도를 해보고자 하여 기술 스택을 파이썬과 장고를 택하게 되었다. 그리고 웹 크롤링은 처음해보는 작업이었기에 이에 대해 조사해본 결과 웹 크롤링을 하는데 있어 파이썬이 Node.js보다 더 적합한 것으로 드러났다. 이는 파이썬에는 웹 크롤링이 가능한 라이브러리가 다수 존재하고 퍼포먼스를 향상할 수 있는 라이브러리 또한 존재하기 때문이다. 그리고 Node.js 같은 경우는 비동기 방식으로 작동하므로 비동기 처리를 해야되고 데이터를 크롤링하기 위해 지속적으로 웹 사이트를 건드려야 하는데 비동기 방식으로 한번에 건드린다면 서버 측에서 디도스 공격으로 착각할 수 있기 때문에 IP 주소가 차단 당할 여지도 있다. 그러므로 다양한 웹 크롤링 라이브러리와 안정성을 확보하기 위해서 파이썬을 주요 언어로 채택을 했다. 웹 프레임워크로서 장고를 택하였는데 이는 MVC 아키텍쳐, ORM, 미들웨어 등을 사용할 수 있고 AWS에서 초기 단계부터 지원한 프레임워크이므로 배포할 때 용이하기 때문이다.



## 기능구현



### 데이터베이스 구조

​	데이터베이스는 플렛폼 정보, 셀럽 정보, 동영상 정보, 구독 정보, 총합 정보가 담긴 테이블들로 이루어졌다. 플렛폼 테이블은 다른 테이블의 기준이 되는 테이블로서, 셀럽의 유저 키, 유저 네임, URL 데이터가 들어간다. 이 테이블에서 자동으로 생성되는 primary key는 다른 테이블의 행을 식별할 수 있는 foreign key로 설정하였다. 셀럽 정보에는 유저 네임, 프로필 사진, 소개에 대한 정보가 들어가고 동영상 테이블에는 동영상 제목, 업로드 날짜, 조회수에 대한 정보가 들어간다. 구독자 테이블에는 구독자 수에 대한 정보 그리고 총합 테이블에는 각 스트리머의 모든 동영상 조회수 총합이 들어간다. 각 플렛폼마다 제공되는 정보가 다르기 때문에 트위치에서 제공되는 데이터만 삽입하였다. 예를 들어 유튜브 같은 경우는 동영상 정보 테이블에는 동영상 조회수 이 외에 동영상 좋아요수, 싫어요수가 존재하나 트위치에서는 동영상 조회수 밖에 제공되는 않기 때문에 제공되지 않는 정보는 null값으로 처리했다.



### 크롤링 및 데이터 삽입

​	기업 측에서 제공해준 엑셀 파일에 셀럽의 유저 네임, URL의 데이터마다 담긴 행이 있으므로 바로 읽어와 데이터베이스에 데이터를 삽입했다. 이는 xlrd란 모듈을 사용하여 각 행에 있는 데이터를 읽어와 바로 데이터베이스로 삽입했다. 유저 정보와 동영상 정보는 request 모듈을 사용하여 트위치 API를 이용해 가져왔다. 트위치 API를 사용할 시, 트위치에서 유저 네임보다는 유저 아이디를 활용할 것을 권장하는데 이는 유저 네임이 변경 가능하므로 셀럽이 유저 네임을 변경할 시, API를 사용하면 유저를 찾을 수 없기 때문이다. 그러므로 API를 사용하여 엑셀에서 유저 네임을 가져와 유저 아이디로 변경하여 유저 정보와 동영상 정보를 가져왔다. 1566명의 셀럽의 정보를 가져와야 했으므로 한 프로세스 당 100명씩 가져오도록 파일을 분할하였다. 

​	셀럽의 정보를 지속적으로 크롤링하여 데이터베이스를 업데이트를 시켜야 했으므로 백그라운드 프로세스로 실행하기 위하여 크론텝을 활용하였다. 1500명이 넘는 데이터를 가져와야 했으므로 이를 한꺼번에 요청할 시, 사용하는 IP가 차단되거나 응답이 지연될 수 있으므로 이를 방지하기 위해 각 파일이 특정 시간에 실행되도록 크론텝을 활용했다. 그리고 각 파일에서도 유저 정보, 동영상 정보, 구독자 정보를 API로 요청할 때마다 time 모듈의 time.sleep()를 걸어주어 요청마다 시차적 간격을 주어 서버를 단시간에 많은 요청을 하는 것을 방지하였다.

![ezgif.com-gif-maker (1)](/Users/damagedcase/Documents/Code States/IM14/ezgif.com-gif-maker (1).gif)

(크론텝으로 스크립트가 실행 될 특정 시간을 설정하여 웹 크롤링을 실행)

![back_2](/Users/damagedcase/Documents/Code States/IM14/back_2.gif)

(크론텝 설정)

![back_3](/Users/damagedcase/Documents/Code States/IM14/back_3.gif)

(웹 크롤링 실행 결과)



## 어려웠던 점 & 해결 방안



### 느린 실행 속도

​	처음에는 파이썬에서 웹 크롤링할 때 주로 쓰이는 selenium과 bs4 라이브러리를 사용하여 정보를 가져오려고 했다. selenium에서 webdriver 사용하여 크롬 브라우저를 실행하고 트위치 사이트에 접속하여 bs4를 활용해 찾고자하는 HTML 요소를 xpath로 크롤링을 하였다. 그러나 실행하는데 너무 오랜 시간이 걸리고 프로젝트 기간 도중 웹 사이트 UI가 바뀌어 크롤링을 못 하여 크롤링 하고자 하는 HTML 요소의 xpath를 수정하는 상황이 발생했다. 웹 사이트 UI 변경에 대한 우려와 실행 속도가 느린 점을 해결하기 위해서 트위치 API를 활용하기로 했다. 트위치 API는 타 API와는 달리 하루에 API를 실행할 수 있는 할당량의 제한이 없으므로 클라인언트 아이디를 발급 받아 헤더에 첨부하여 요청을 하면 바로 데이터를 빠르게 받을 수 있어 selenium과 bs4 라이브러리를 사용하는 것보다 더 신속하고 안정적이어서 위의 문제를 해결했다.

​	트위치 API를 사용하여 한 명의 셀럽 정보를 더 신속하게 받아오는 부분은 성공했지만 크론텝으로 실행할 파일이 총 16개이고 파일 당 셀럽 100명의 정보를 가져와야 했으므로 기본 반복문으로 실행하면 10명 기준으로 59초 정도 걸려 약 10분 정도 소요되었다. 이를 더 빠른 속도로 처리하기 위하여 파이썬에서 기본으로 제공되는 multprocessing 모듈을 활용하였다. 기본적으로 파이썬은 global interpreter lock에 의하여 한 CPU 코어만 사용하도록 되어있어 파이썬 인터프리터는 하나의 쓰레드에서만 실행되도록 제한이 걸려있다. 그러나, multiprocessing 모듈은 global interpreter lock을 우회하여 CPU의 프로세서 개수대로 동시에 코드를 실행할 수 있게끔 해준다. 이러한 장점을 활용할 수 있도록 multiprocessing 모듈에서는 Pool이란 클래스가 제공된다. Pool은 각 다른 프로세스에 작업을 할당하여 처리 속도를 높일 수 있다. pool.map을 사용하면 주어진 pool의 개수에 맞춰 배열에 있는 값들을 할당하여 함수를 실행한다. 예를 들어, 배열 안에 구독자수를 가져와야 할 트위치 스트리머 개수가 10고 pool 개수를 2개로 설정하면 각 풀마다 5개의 유저 네임을 동시에 처리할 수 있다. 이를 활용한 결과 10분이 걸리던 작업이 7분으로 줄은 효과를 봤다.



### 데몬 탐색

​	데몬이란 백그라운드 상태에서 주어진 작업이나 서비스를 실행하도록 지속적으로 실행되는 프로세스이다. 그래서 화면에서 직접 보이지 않는 곳에서 작동되며 이는 컴퓨터가 부팅되면서 메모리에 로딩되며 컴퓨터가 종료될 때가지 계속 프로세스가 실행된다. multiprocessing에 데몬이 포함되어 있어 Pool과 같이 사용하려 했으나 multiprocessing 데몬 같은 경우는 주어진 작업만 끝나면 바로 프로세스가 종료된다는 문제점을 지니고 있었다. 데몬으로 크롤링하는 이유는 백그라운드 상태에서 프로세스가 종료되지 않고 크롤링을 해야되는데 프로세스가 종료되면 이 데몬을 쓸 이유가 없어지기 때문이다. multiprocessing 공식 문서를 확인해보니 multiprocessing에 있는 데몬은 일반적인 데몬과 다르기 때문에 이에 대한 대안을 탐색해 보았다.

​	데몬에 대해서 더 알아보던 도중 크론이라는 것을 찾았는데 크론은 데몬 프로세서의 한 종류로서 설정된 특정 시간이나 간격에 따라 주어진 작업을 수행한다. 크롤링이나 API 사용의 best practice 중에 하나가 서버에 동시에 너무 많은 요청을 하지 않는 것인데 실행해야 할 작업을 시간 별로 나눠주면 이를 지킬 수 있어 적합한 데몬이라고 판단되어 이를 사용하기로 했다. 파이썬에서 어떻게 쓸 수 있을까 찾아보다가 터미널에서 직접 crontab을 사용하기로 했다. 크론텝은 유닉스 계열 컴퓨터에 내장되어 있는 시간 기반 스케쥴러인데 크론텝 스크립트 작성 방식은 별 5개에 원하는 날짜 및 시간을 설정한 후 실행하고자 하는 파일과 명령어를 지정하면 정해준 시간에 파일이 실행된다. 

![image-20191028202000719](/Users/damagedcase/Library/Application Support/typora-user-images/image-20191028202000719.png)

​	크론텝에서 스크립트가 실행될 특정 시간을 설정하고 이가 원활하게 돌아가는지 보려했으나 파이썬 인터프리터와 스크립트를 못 찾겠다는 에러가 발생했다. 에러에 대해서 알아보니 크론텝은 루트에서 실행되고 파이썬 인터프리터의 위치를 지정해야 되기 때문에 실행할 스크립트와 파이썬 인터프리터의 절대 경로를 설정해야 된다. 그러므로 루트 폴더부터 크론텝이 실행할 스크립트 절대 경로까지 가도록 cd 명령어를 쓰고 파이썬 인터프리터의 절대 경로도 지정해야된다. 그리고 크론텝이 모듈이나 페키지가 어디 설치되어 있는지도 역시 모르기 때문에 가상 환경 폴더도 역시 같이 절대 경로를 설정해줘야 한다. 이 모든 설정을 거쳐 크론텝이 의도한 바와 같이 작동하는 것을 확인했다.



## 프로젝트를 마치며

​	기업협업 프로젝트를 진행하며 많은 것을 배웠지만 동시에 아쉬운 점도 있었다. 셀럽의 흥망성쇄를 파악하기 위해서 각 셀럽의 구독자 수나 동영상 조회수를 날짜별로 차이를 구하여 비교하면 파악이 될 수 있는데 테이블 구현과 알고리즘만 작성하고 제대로 구현이 되는지 테스트를 못 해봤다. 그리고 트위치 셀럽 수가 많아 16개의 파일로 나눴는데 파일마다 크롤링 할 셀럽만 다르고 사용되는 함수는 다 동일하기 때문에 반복되는 함수를 모듈화 했으면 더 깔끔한 스크립트를 작성할 수 있었을 것 같다. 그리고 위에서 언급한 바와 같이 트위치 API는 유저 네임보다 유저 아이디를 쓸 것을 권장하는데 처음에는 트위치 유저 네임을 유저 아이디로 변환해주는 크롬 익스텐션을 사용해 하나 하나 타입하면서 변환을 했었다. 그러다 보니 많이 시간이 지체되고 피로도는 상당했다. 만약에 엑셀 파일에서 유저 네임을 xlrd 사용해 다 추출해와서 트위치 API를 활용하여 유저 아이디를 구했으면 더 깔끔하고 효율적으로 작업을 할 수 있었을 것 같다는 아쉬움이 크게 들었다.

​	위와 같은 아쉬운 점들도 있었지만 프로젝트를 얻어 간 것이 더 컸던것 같다. 첫 번째는 새로운 언어와 프레임워크를 배우고 시도하는 것에 대한 두려움을 극복했다. 프로젝트 초기 단계에서 어떤 언어와 프레임워크를 사용할지에 대해 팀원들과 논의를 할 때 개인적으로 Node.js를 사용하고 싶었다. 프로젝트 기간이 한 달 밖에 안 되고 새로운 언어에 적응하는데 많은 시간을 투자할까봐 두려웠는데 파이썬을 배우면서 직관적이고 편하다는 것을 느꼈다. 그러나, 장고는 아직 익숙해지지 않아 이는 더 공부를 해봐야 될거 같다. 새로운 시도에 대한 두려움을 극복해보니 앞으로 새로운 언어와 프레임워크를 배울 때 더 편하고 안정된 마음으로 다가설 수 있을 것 같다. 두 번째는 남한테 도움을 요청하는 용기다. 팀원들이 각자 맡은 역할을 수행하느라 고생이 많은데 괜히 도움을 요청해서 피해를 끼치기 싫었다. 그러나, 혼자서 해결하려다가 오히려 시간이 지체되는 상황이 발생하여 팀원이 도움을 줘서 금방 해결했고 도움이 필요하면 얼마든지 요청해도 괜찮다는 조언을 해줬다. 혼자서 해결하기 너무 벅찰 때, 도움을 요청하여 해결하는 것이 오히려 협업에 더 도움이 될 수 있다는 것을 배울 수 있었다.